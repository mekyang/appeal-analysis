from config import *
from extract_content import ContentExtractor
from data_analysis import TaxClusteringEngine
from cluster_eval import ClusterEvaluator
from data_sanitizer import TaxDataSanitizer
from cluster_tagger import LLMKeywordExtractor
from excel_handle import *
import pandas as pd

content_extractor = ContentExtractor()

# def deal_data():
#     df = read_excel(EXCEL_PATH, sheet_name=0, header=0)

#     # æå–å†…å®¹
#     extracted_contents = content_extractor.extract_content(df, 'ä¸šåŠ¡å†…å®¹')

#     # ä¿å­˜ç»“æœåˆ°æ–°çš„Excelæ–‡ä»¶
#     output_df = pd.DataFrame({'Extracted Content': extracted_contents})
#     save_excel(output_df, SAVE_PATH)

def deal_data():
    print(f"ğŸ“‚ å¼€å§‹è¯»å–åŸå§‹æ–‡ä»¶: {EXCEL_PATH} ...")
    try:
        # 1. è¯»å–åŸå§‹æ•°æ®
        df = read_excel(EXCEL_PATH, sheet_name=0, header=0)
        df['Trace_ID'] = df.index + 2 
        print(f"âœ… å·²ç”Ÿæˆè¿½è¸ªåºå· (Trace_ID)ï¼ŒèŒƒå›´: {df['Trace_ID'].min()} - {df['Trace_ID'].max()}")
        
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return

    # --- åˆå§‹åŒ–å·¥å…·é“¾ ---
    print("ğŸ”§ åˆå§‹åŒ–å¤„ç†å·¥å…·...")
    extractor = ContentExtractor() 
    sanitizer = TaxDataSanitizer(use_ner=True) 

    print("1ï¸âƒ£ æ­£åœ¨æå–æ­£æ–‡å¹¶å»é™¤åºŸè¯...")
    raw_content_series = extractor.extract_content(df, 'ä¸šåŠ¡å†…å®¹')

    print("2ï¸âƒ£ æ­£åœ¨è¿›è¡Œéšç§è„±æ•...")
    temp_df = pd.DataFrame({'temp_text': raw_content_series})
    sanitizer.process_dataframe(temp_df, 'temp_text')

    output_df = pd.DataFrame({
        'Trace_ID': df['Trace_ID'],              
        'Original_Content': df['ä¸šåŠ¡å†…å®¹'],      
        'Extracted_Content': temp_df['temp_text_sanitized'] 
    })
    
    initial_count = len(output_df)
    output_df = output_df[output_df['Extracted_Content'].str.strip() != '']
    final_count = len(output_df)
    
    print(f"ğŸ§¹ å·²è¿‡æ»¤æ— æ•ˆç©ºè¡Œ: {initial_count} -> {final_count} (åˆ é™¤äº† {initial_count - final_count} æ¡)")

    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœåˆ°: {SAVE_PATH} ...")
    save_excel(output_df, SAVE_PATH)
    print("âœ… æ•°æ®é¢„å¤„ç†å®Œæ¯•ï¼")

def main():
    # è¯»å–Excelæ–‡ä»¶
    if not check_file_exists(SAVE_PATH):
        print("æå–å†…å®¹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ­£åœ¨ç”Ÿæˆ...")
        deal_data()
    
    try:
        df = read_excel(SAVE_PATH, sheet_name=0, header=0)
    except Exception as e:
        print(f"Error reading the Excel file: {e}")
        return

    # åˆ›å»º TaxClusteringEngine å®ä¾‹
    clustering_engine = TaxClusteringEngine(EMBEDDING_MODEL_NAME)

    # æ‰§è¡Œåˆ†æ
    text = df[DATA_COLUMN].dropna().astype(str).tolist()
    text = [t for t in text if len(t.strip()) > 0]
    original = df['Original_Content'].tolist()

    print(f"æœ‰æ•ˆæ–‡æœ¬æ•°é‡: {len(text)}")

    load_cluster = input("æ˜¯å¦åŠ è½½ä¹‹å‰çš„èšç±»çŠ¶æ€ï¼Ÿ(y/n): ").strip().lower()
    if load_cluster == 'y':
        # å°è¯•åŠ è½½ä¹‹å‰çš„çŠ¶æ€
        if clustering_engine.load_state(STATE_FILE):
            results_df = clustering_engine.get_results()
        else:
            results_df = clustering_engine.run_analysis(text, original)
            clustering_engine.save_state(STATE_FILE)

    else:
        # å¦‚æœæ²¡æœ‰çŠ¶æ€æ–‡ä»¶ï¼Œåˆ™è¿è¡Œå®Œæ•´åˆ†ææµç¨‹          
        results_df = clustering_engine.run_analysis(text, original)
        clustering_engine.save_state(STATE_FILE)

    #ä¿å­˜åˆ†æç»“æœ
    cluster_eval = ClusterEvaluator(df=results_df, embeddings=clustering_engine.get_embeddings())
    cluster_eval.run_full_report()
    clustering_engine.save_results(OUTPUT_DIR)

    # clustering_engine.merge_similar_clusters(threshold=0.92)
    # clustering_engine.save_results('æœ€ç»ˆç»“æœ_å·²åˆå¹¶.xlsx')

if __name__ == "__main__":
    # æ¨¡æ‹Ÿæ•°æ®
    #main()
    # data = read_excel(OUTPUT_DIR)
    # df = pd.DataFrame(data)

    # 1. åˆå§‹åŒ– (æ›¿æ¢ä¸ºä½ çš„ Key)
    # æ¨èä½¿ç”¨ DeepSeekï¼Œä¾¿å®œä¸”ä¸­æ–‡èƒ½åŠ›å¼º
    # extractor = LLMKeywordExtractor(
    #     api_key="sk-f1fec6b90628475ba7ce12b2c389c85a", 
    #     base_url="https://api.deepseek.com"
    # )

    # # 2. è¿è¡Œæå–
    # df_result = extractor.extract_keywords(df, text_col='Text')

    # # 3. æŸ¥çœ‹ç»“æœ
    # save_excel(df_result[['Cluster', 'LLM_Keywords']].drop_duplicates(), FINAL_DIR)

    # join_cluster_summary(
    #     detail_file_path=OUTPUT_DIR, 
    #     summary_file_path=FINAL_DIR, 
    #     output_path="æœ€ç»ˆå®Œæ•´æ±‡æŠ¥è¡¨.xlsx",
    #     on_key="Cluster"  # ç¡®ä¿ä¸¤ä¸ª Excel é‡Œéƒ½æœ‰è¿™ä¸€åˆ—ï¼Œä¸”åˆ—åå®Œå…¨ä¸€è‡´
    # )
    df = read_excel(TEST_FILE)
    df = content_extractor.extract_content(df=df,column_name='Trace_ID')
    save_excel(df, TEST_FILE)
