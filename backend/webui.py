import streamlit as st
import pandas as pd
import os
import time

# å¯¼å…¥é…ç½®
from config import *

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from extract_content import ContentExtractor_12366, ContentExtractor_12345, ContentExtractor_ZN
from data_sanitizer import TaxDataSanitizer
from data_analysis import TaxClusteringEngine 
from cluster_eval import ClusterEvaluator
from cluster_tagger import LLMKeywordExtractor
from excel_handle import *

# =====================================================================
# é¡µé¢é…ç½®
# =====================================================================
st.set_page_config(
    page_title="ç¨åŠ¡è¯‰æ±‚åˆ†æç³»ç»Ÿ Pro",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰æ ·å¼
st.markdown("""
    <style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
    .success-box {
        background-color: #d4edda;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
    .error-box {
        background-color: #f8d7da;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
    </style>
""", unsafe_allow_html=True)

# =====================================================================
# ä¾§è¾¹æ å¯¼èˆª
# =====================================================================
st.sidebar.title("ğŸ“‹ å¯¼èˆªèœå•")
page = st.sidebar.radio(
    "é€‰æ‹©åŠŸèƒ½æ¨¡å—",
    ["ğŸ  é¦–é¡µ", "ğŸ“¤ æ•°æ®é¢„å¤„ç†", "ğŸ§  æ–‡æœ¬èšç±»åˆ†æ", "ğŸ“Š èšç±»è¯„ä¼°", "ğŸ·ï¸ LLMå…³é”®è¯æå–", "ğŸ“ˆ ç»“æœæŸ¥çœ‹"]
)

# =====================================================================
# é¦–é¡µ
# =====================================================================
if page == "ğŸ  é¦–é¡µ":
    st.title("ğŸ¯ ç¨åŠ¡è¯‰æ±‚åˆ†æç³»ç»Ÿ")
    st.markdown("---")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ç³»ç»Ÿç‰ˆæœ¬", "v2.0", "Pro")
    with col2:
        st.metric("å¤„ç†æ¨¡å‹", "SBERT + HDBSCAN", "ç”Ÿäº§çº§")
    with col3:
        st.metric("çŠ¶æ€", "âœ… å°±ç»ª", "å¯ç”¨")
    
    st.markdown("---")
    st.subheader("ğŸ“š åŠŸèƒ½ä»‹ç»")
    
    features = {
        "ğŸ“¤ æ•°æ®é¢„å¤„ç†": "âœ“ å†…å®¹æå– âœ“ éšç§è„±æ• âœ“ æ•°æ®æ¸…æ´—",
        "ğŸ§  æ–‡æœ¬èšç±»": "âœ“ SBERTç¼–ç  âœ“ çŠ¶æ€ä¿å­˜ âœ“ ç›¸ä¼¼ç°‡åˆå¹¶",
        "ğŸ“Š èšç±»è¯„ä¼°": "âœ“ è½®å»“ç³»æ•° âœ“ æ•£ç‚¹å›¾å¯è§†åŒ– âœ“ ç›¸ä¼¼åº¦åˆ†æ",
        "ğŸ·ï¸ LLMæå–": "âœ“ DeepSeek/GPTè°ƒç”¨ âœ“ å…³é”®è¯å½’çº³ âœ“ æ™ºèƒ½é‡‡æ ·",
        "ğŸ“ˆ ç»“æœå¯¼å‡º": "âœ“ Excelæ±‡æ€» âœ“ ç»Ÿè®¡åˆ†æ âœ“ æŠ¥è¡¨ç”Ÿæˆ"
    }
    
    for title, desc in features.items():
        st.success(f"**{title}**: {desc}")
    
    st.info("ğŸ’¡ å»ºè®®æµç¨‹: æ•°æ®é¢„å¤„ç† â†’ æ–‡æœ¬èšç±» (ä¿å­˜çŠ¶æ€) â†’ èšç±»è¯„ä¼° â†’ LLMæå– â†’ ç»“æœæŸ¥çœ‹")

# =====================================================================
# æ•°æ®é¢„å¤„ç†é¡µé¢ (ä¿®å¤ç‰ˆï¼šè§£å†³æŒ‰é’®æ— æ³•ç‚¹å‡»é—®é¢˜)
# =====================================================================
elif page == "ğŸ“¤ æ•°æ®é¢„å¤„ç†":
    st.title("ğŸ“¤ æ•°æ®é¢„å¤„ç†æ¨¡å—")
    st.markdown("æ­¥éª¤: å†…å®¹æå– â†’ éšç§è„±æ• â†’ ä¿å­˜ç»“æœ")
    st.markdown("---")
    
    # --- 1. åˆå§‹åŒ– Session State (å…³é”®æ­¥éª¤) ---
    # ç”¨æ¥â€œè®°ä½â€å¤„ç†åçš„æ•°æ®ï¼Œé˜²æ­¢é¡µé¢åˆ·æ–°åæ•°æ®ä¸¢å¤±
    if 'proc_df' not in st.session_state:
        st.session_state['proc_df'] = None
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("1ï¸âƒ£ æ–‡ä»¶ä¸Šä¼ ")
        uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx", "xls"])
        
        extractor_type = st.selectbox(
            "é€‰æ‹©æå–å™¨ç±»å‹",
            ["12366å·¥å•æå–å™¨", "12345å·¥å•æå–å™¨", "å¾çº³äº’åŠ¨ç®€æ˜“æå–å™¨"]
        )
    
    with col2:
        st.subheader("2ï¸âƒ£ å¤„ç†é…ç½®")
        use_ner = st.checkbox("å¯ç”¨NERæ¨¡å‹è„±æ•", value=True, help="ä½¿ç”¨BERTæ¨¡å‹è¯†åˆ«å…¬å¸åï¼ˆæ›´å‡†ç¡®ä½†æ›´æ…¢ï¼‰")
        column_name = st.text_input("è¾“å…¥å†…å®¹åˆ—å", "ä¸šåŠ¡å†…å®¹")
    
    st.markdown("---")
    
    # --- 2. å¤„ç†é€»è¾‘ (ç‚¹å‡»ååªè´Ÿè´£å¤„ç†æ•°æ®å¹¶å­˜å…¥ State) ---
    if st.button("ğŸš€ å¼€å§‹å¤„ç†", key="preprocess_btn"):
        if uploaded_file is None:
            st.error("âŒ è¯·å…ˆä¸Šä¼ Excelæ–‡ä»¶")
        else:
            try:
                # åˆ›å»ºè¿›åº¦æ¡å®¹å™¨
                progress_container = st.container()
                progress_bar = progress_container.progress(0, text="åˆå§‹åŒ–...")
                
                # è¯»å–æ–‡ä»¶
                progress_bar.progress(5, text="ğŸ“– æ­£åœ¨è¯»å–æ–‡ä»¶...")
                df = pd.read_excel(uploaded_file)
                st.success(f"âœ… æ–‡ä»¶åŠ è½½æˆåŠŸï¼Œå…± {len(df)} è¡Œ")
                
                # å†…å®¹æå–
                progress_bar.progress(20, text="ğŸ” æ­£åœ¨æå–å†…å®¹...")
                if extractor_type == "12366å·¥å•æå–å™¨":
                    extractor = ContentExtractor_12366()
                elif extractor_type == "12345å·¥å•æå–å™¨":
                    extractor = ContentExtractor_12345()
                elif extractor_type == "å¾çº³äº’åŠ¨ç®€æ˜“æå–å™¨":
                    extractor = ContentExtractor_ZN()
                
                df['Extracted_Content'] = extractor.extract_content(df, column_name)
                
                # éšç§è„±æ•
                if use_ner:
                    progress_bar.progress(50, text="ğŸ” æ­£åœ¨è¿›è¡Œéšç§è„±æ• (GPUæ¨ç†ä¸­)...")
                    
                    # åˆ›å»º NER è¿›åº¦å›è°ƒ
                    def ner_progress(current, total, stage):
                        pct = int(50 + (current / total) * 30)
                        progress_bar.progress(min(pct, 80), text=f"ğŸ” {stage} ({current}/{total})")
                    
                    sanitizer = TaxDataSanitizer(use_ner=use_ner)
                    df = sanitizer.process_dataframe(df, 'Extracted_Content', 'Sanitized_Content', progress_callback=ner_progress)
                else:
                    progress_bar.progress(50, text="âœ“ è·³è¿‡NERï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼...")
                    sanitizer = TaxDataSanitizer(use_ner=False)
                    df = sanitizer.process_dataframe(df, 'Extracted_Content', 'Sanitized_Content')

                # æ•°æ®æ¸…æ´—
                progress_bar.progress(80, text="ğŸ§¹ æ­£åœ¨æ¸…æ´—æ•°æ®...")
                initial_count = len(df)
                df = df[df['Sanitized_Content'].str.strip() != '']
                final_count = len(df)
                
                st.info(f"ğŸ§¹ å·²è¿‡æ»¤ç©ºè¡Œ: {initial_count} â†’ {final_count} (åˆ é™¤ {initial_count - final_count} è¡Œ)")
                
                # ã€å…³é”®ã€‘å°†å¤„ç†å¥½çš„ df å­˜å…¥ session_state
                progress_bar.progress(100, text="âœ… å¤„ç†å®Œæˆï¼")
                time.sleep(0.5)
                progress_container.empty()  # æ¸…é™¤è¿›åº¦æ¡
                
                st.session_state['proc_df'] = df
                st.success("âœ… å¤„ç†å®Œæˆï¼ç»“æœå·²ç¼“å­˜ï¼Œè¯·åœ¨ä¸‹æ–¹æŸ¥çœ‹å’Œå¯¼å‡ºã€‚")
                
            except Exception as e:
                st.error(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")

    # --- 3. ç»“æœå±•ç¤ºä¸ä¿å­˜é€»è¾‘ (ç‹¬ç«‹äºæŒ‰é’®ä¹‹å¤–) ---
    # åªè¦ State é‡Œæœ‰æ•°æ®ï¼Œå°±æ˜¾ç¤ºè¿™éƒ¨åˆ†ç•Œé¢
    if st.session_state['proc_df'] is not None:
        df = st.session_state['proc_df']
        
        st.markdown("---")
        st.subheader("ğŸ“‹ é¢„è§ˆå¤„ç†ç»“æœ")
        
        # é¢„è§ˆ
        preview_cols = st.multiselect(
            "é€‰æ‹©æ˜¾ç¤ºåˆ—",
            df.columns.tolist(),
            default=['Extracted_Content', 'Sanitized_Content']
        )
        st.dataframe(df[preview_cols].head(10), use_container_width=True)
        
        # å¯¼å‡ºåŒºåŸŸ
        st.subheader("ğŸ’¾ å¯¼å‡ºç»“æœ")
        col_export1, col_export2 = st.columns([2, 1])
        with col_export1:
            output_filename = st.text_input("è¾“å‡ºæ–‡ä»¶å", "processed_data")
        with col_export2:
            export_format = st.radio("æ ¼å¼é€‰æ‹©", ["Excel", "CSV"], horizontal=True)
        
        # Excel ä¸‹è½½æŒ‰é’®
        if export_format == "Excel":
            import io
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                df.to_excel(writer, index=False, sheet_name='Sheet1')
            excel_buffer.seek(0)
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ Excel",
                data=excel_buffer,
                file_name=f"{output_filename}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="primary"
            )
        # CSV ä¸‹è½½æŒ‰é’®
        else:
            csv_buffer = df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ CSV",
                data=csv_buffer,
                file_name=f"{output_filename}.csv",
                mime="text/csv",
                type="primary"
            )
# =====================================================================
# ğŸ§  æ–‡æœ¬èšç±»åˆ†æé¡µé¢ (ä¿®å¤ç‰ˆV3 - å·²æ•´åˆ)
# =====================================================================
elif page == "ğŸ§  æ–‡æœ¬èšç±»åˆ†æ":
    st.title("ğŸ§  æ–‡æœ¬èšç±»åˆ†æ (é«˜çº§ç‰ˆ)")
    st.markdown("æ”¯æŒ **SBERTç¼–ç ** + **å‚æ•°å¾®è°ƒ** + **çŠ¶æ€æ¢å¤** + **è¯­ä¹‰åˆå¹¶**")
    st.markdown("---")

    # --- Session State åˆå§‹åŒ– ---
    if 'cluster_engine' not in st.session_state:
        st.session_state['cluster_engine'] = None

    # ==================================================
    # ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•°æ®åŠ è½½ä¸ä»»åŠ¡åˆ›å»º
    # ==================================================
    with st.expander("ğŸ“‚ 1. æ•°æ®æºé…ç½® (å¼€å§‹æ–°ä»»åŠ¡æˆ–åŠ è½½å†å²)", expanded=True):
        col_src1, col_src2 = st.columns(2)
        
        # --- å·¦ä¾§ï¼šåŠ è½½å†å² ---
        with col_src1:
            st.subheader("æ–¹å¼ A: åŠ è½½å†å²çŠ¶æ€")
            if os.path.exists(STATE_FILE):
                st.success(f"âœ… æ£€æµ‹åˆ°å­˜æ¡£: `{os.path.basename(STATE_FILE)}`")
                if st.button("ğŸ“‚ åŠ è½½å†å²çŠ¶æ€ (è·³è¿‡æ¼«é•¿ç¼–ç )", key="load_state_btn"):
                    try:
                        with st.spinner("æ­£åœ¨æ¢å¤å‘é‡æ•°æ®ä¸èšç±»ç»“æœ..."):
                            engine = TaxClusteringEngine(EMBEDDING_MODEL_NAME)
                            if engine.load_state(STATE_FILE):
                                st.session_state['cluster_engine'] = engine
                                st.success(f"å·²æ¢å¤çŠ¶æ€ï¼ŒåŒ…å« {len(engine.get_results())} æ¡æ•°æ®")
                                time.sleep(0.5)
                                st.rerun()
                    except Exception as e:
                        st.error(f"åŠ è½½å¤±è´¥: {str(e)}")
            else:
                st.warning("âš ï¸ æœªæ‰¾åˆ°å†å²çŠ¶æ€æ–‡ä»¶ (é¦–æ¬¡è¿è¡Œè¯·ä½¿ç”¨å³ä¾§)")

        # --- å³ä¾§ï¼šä¸Šä¼ æ–°æ–‡ä»¶ ---
        with col_src2:
            st.subheader("æ–¹å¼ B: ä¸Šä¼ æ–°æ–‡ä»¶ (é‡æ–°è·‘)")
            input_file = st.file_uploader("ä¸Šä¼ é¢„å¤„ç†åçš„Excel", type=["xlsx", "xls"], key="cluster_input")
            text_column = st.text_input("æ–‡æœ¬åˆ—å", "Sanitized_Content")
            original_column = st.text_input("IDåˆ—å", "ä¸šåŠ¡ç¼–å·")

    # å¦‚æœä¸Šä¼ äº†æ–°æ–‡ä»¶ï¼Œæ˜¾ç¤ºâ€œå¼€å§‹è¿è¡Œâ€çš„é…ç½®é¢æ¿
    if input_file is not None:
        st.info("æ£€æµ‹åˆ°æ–°æ–‡ä»¶ä¸Šä¼ ï¼Œè¯·é…ç½®å‚æ•°å¹¶å¼€å§‹åˆ†æï¼š")
        with st.form("new_analysis_form"):
            c1, c2, c3, c4 = st.columns(4)
            with c1: n_neighbors = st.slider("n_neighbors", 5, 50, 15)
            with c2: n_components = st.slider("n_components", 2, 10, 5)
            with c3: min_cluster_size = st.slider("min_cluster_size", 3, 100, 10)
            with c4: keyword_top_n = st.number_input("å…³é”®è¯æ•°", 3, 10, 5)
            
            # ä¿å­˜é€‰é¡¹
            auto_save_new = st.checkbox("è¿è¡Œå®Œæˆåè‡ªåŠ¨ä¿å­˜çŠ¶æ€æ–‡ä»¶", value=True)
            
            submitted = st.form_submit_button("ğŸš€ å¼€å§‹å®Œæ•´åˆ†æ (SBERTç¼–ç )")
            
            if submitted:
                try:
                    df = pd.read_excel(input_file)
                    if text_column not in df.columns:
                        st.error(f"âŒ åˆ—å '{text_column}' ä¸å­˜åœ¨ï¼")
                    else:
                        texts = df[text_column].dropna().astype(str).tolist()
                        texts = [t for t in texts if len(t.strip()) > 0]
                        
                        # å°è¯•è·å–ID,å¦‚æœè¾“å…¥çš„ä¸å­˜åœ¨åˆ™è‡ªåŠ¨æ£€æµ‹ï¼Œæ²¡æœ‰åˆ™ä¸ºç©º

                        original_column_list = None
                        for col in ['Trace_ID', 'å·¥å•ç¼–å·', 'ID', 'åºå·', 'ä¸šåŠ¡ç¼–å·', original_column]:
                            if col in df.columns:
                                original_column_list = df[col].tolist()
                                break

                        # åˆ›å»ºè¿›åº¦å®¹å™¨
                        progress_placeholder = st.empty()
                        with progress_placeholder.container():
                            progress_bar = st.progress(0, text="ğŸš€ åˆå§‹åŒ–èšç±»å¼•æ“...")
                        
                        try:
                            progress_bar.progress(10, text="ğŸ¤– åŠ è½½SBERTæ¨¡å‹...")
                            engine = TaxClusteringEngine(EMBEDDING_MODEL_NAME)
                            
                            # å®šä¹‰åˆ†æè¿›åº¦å›è°ƒ
                            def analysis_progress(current, total, stage):
                                progress_bar.progress(min(current, 99), text=stage)
                            
                            progress_bar.progress(15, text="ğŸ§  å¼€å§‹SBERTç¼–ç ä¸èšç±»...")
                            # è¿™é‡Œå¼•æ“ä¼šå†…éƒ¨æ˜¾ç¤ºç¼–ç è¿›åº¦
                            engine.run_analysis(
                                texts, 
                                original=original_column_list,
                                n_neighbors=n_neighbors,
                                n_components=n_components,
                                min_cluster_size=min_cluster_size,
                                keyword_top_n=keyword_top_n,
                                progress_callback=analysis_progress
                            )
                            st.session_state['cluster_engine'] = engine
                            
                            progress_bar.progress(95, text="ğŸ’¾ ä¿å­˜çŠ¶æ€ä¸­...")
                            if auto_save_new:
                                engine.save_state(STATE_FILE)
                            
                            progress_bar.progress(100, text="âœ… åˆ†æå®Œæˆï¼")
                            time.sleep(0.5)
                            progress_placeholder.empty()
                            
                            if auto_save_new:
                                st.success("âœ… åˆ†æå®Œæˆå¹¶å·²ä¿å­˜çŠ¶æ€ï¼")
                            else:
                                st.success("âœ… åˆ†æå®Œæˆ (æœªä¿å­˜çŠ¶æ€)ï¼")
                            
                            time.sleep(1)
                            st.rerun()
                        except Exception as inner_e:
                            progress_placeholder.empty()
                            st.error(f"åˆ†æå¤±è´¥: {str(inner_e)}")
                except Exception as e:
                    st.error(f"åˆ†æå¤±è´¥: {str(e)}")

    st.markdown("---")

    # ==================================================
    # ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒæ“ä½œå° (ä»…åœ¨æœ‰æ•°æ®æ—¶æ˜¾ç¤º)
    # ==================================================
    if st.session_state['cluster_engine'] is not None:
        engine = st.session_state['cluster_engine']
        
        # --- å…¨å±€æ§åˆ¶æ  ---
        st.subheader("ğŸ› ï¸ 2. èšç±»æ§åˆ¶å°")
        
        # æ”¾ç½®ä¸€ä¸ªå…¨å±€å¼€å…³ï¼Œæ§åˆ¶æ˜¯å¦è‡ªåŠ¨ä¿å­˜
        col_opt1, col_opt2 = st.columns([1, 3])
        with col_opt1:
            enable_auto_save = st.toggle("æ“ä½œåè‡ªåŠ¨æ›´æ–°çŠ¶æ€æ–‡ä»¶", value=True, help="å¼€å¯åï¼Œæ¯æ¬¡é‡èšç±»æˆ–åˆå¹¶éƒ½ä¼šè¦†ç›– STATE_FILE")
        with col_opt2:
            if st.button("ğŸ’¾ æ‰‹åŠ¨ä¿å­˜å½“å‰çŠ¶æ€"):
                engine.save_state(STATE_FILE)
                st.toast("âœ… çŠ¶æ€å·²æ‰‹åŠ¨ä¿å­˜ï¼")

        # --- é€‰é¡¹å¡æ“ä½œ ---
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ”„ å¿«é€Ÿé‡èšç±»", "ğŸ§© åˆå¹¶ç›¸ä¼¼ç°‡", "ğŸ“Š ç»“æœé¢„è§ˆ", "ğŸ“¤ å¯¼å‡ºæ•°æ®"])
        
        # === Tab 1: å¿«é€Ÿé‡èšç±» ===
        with tab1:
            st.markdown("##### è°ƒæ•´å¯†åº¦å‚æ•° (æ— éœ€é‡è·‘å‘é‡åŒ–)")
            col_r1, col_r2, col_r3 = st.columns(3)
            with col_r1:
                re_min_size = st.slider("æ–° min_cluster_size", 3, 100, 10, key="re_min")
            with col_r2:
                re_neighbors = st.slider("æ–° n_neighbors", 5, 50, 15, key="re_neigh")
            with col_r3:
                re_top_n = st.number_input("æ–° å…³é”®è¯æ•°", 1, 10, 5, key="re_top")
                
            if st.button("âš¡ æ‰§è¡Œé‡èšç±»", type="primary"):
                with st.spinner("æ­£åœ¨é‡èšç±»..."):
                    engine.re_cluster(n_neighbors=re_neighbors, min_cluster_size=re_min_size, keyword_top_n=re_top_n)
                    
                    if enable_auto_save:
                        engine.save_state(STATE_FILE)
                        st.success("âœ… é‡èšç±»å®Œæˆ (çŠ¶æ€å·²è‡ªåŠ¨ä¿å­˜)")
                    else:
                        st.success("âœ… é‡èšç±»å®Œæˆ (ä»…å†…å­˜æ›´æ–°)")
                    
                    time.sleep(0.5)
                    st.rerun()

        # === Tab 2: åˆå¹¶ç›¸ä¼¼ç°‡ ===
        with tab2:
            st.markdown("##### è¯­ä¹‰åˆå¹¶")
            st.info("åŠŸèƒ½è¯´æ˜ï¼šåŸºäºä½™å¼¦ç›¸ä¼¼åº¦ï¼Œå°†è¯­ä¹‰éå¸¸æ¥è¿‘çš„ç°‡åˆå¹¶ä¸ºä¸€ä¸ªï¼ˆä¾‹å¦‚ï¼š'å¼€å‘ç¥¨' å’Œ 'å¼€å…·å‘ç¥¨'ï¼‰ã€‚")
            
            merge_threshold = st.slider("ç›¸ä¼¼åº¦é˜ˆå€¼ (Threshold)", 0.80, 1.00, 0.92, 0.01, help="é«˜äºæ­¤ç›¸ä¼¼åº¦çš„ç°‡å°†è¢«åˆå¹¶ã€‚æ¨è 0.90 - 0.95")
            
            if st.button("ğŸ§© å¼€å§‹åˆå¹¶ç›¸ä¼¼ç°‡", type="primary"):
                with st.spinner("æ­£åœ¨è®¡ç®—ç°‡ä¸­å¿ƒå¹¶åˆå¹¶..."):
                    # è°ƒç”¨åˆå¹¶å‡½æ•°
                    engine.merge_similar_clusters(threshold=merge_threshold)
                    
                    if enable_auto_save:
                        engine.save_state(STATE_FILE)
                        st.success("âœ… åˆå¹¶æ“ä½œå®Œæˆ (çŠ¶æ€å·²è‡ªåŠ¨ä¿å­˜)")
                    else:
                        st.success("âœ… åˆå¹¶æ“ä½œå®Œæˆ (ä»…å†…å­˜æ›´æ–°)")
                        
                    time.sleep(1)
                    st.rerun()

        # === Tab 3: ç»“æœé¢„è§ˆ ===
        with tab3:
            results_df = engine.get_results()
            if results_df is not None:
                # ç»Ÿè®¡
                n_clusters = len(results_df[results_df['Cluster'] != -1]['Cluster'].unique())
                n_noise = (results_df['Cluster'] == -1).sum()
                
                c1, c2, c3 = st.columns(3)
                c1.metric("æ€»è¡Œæ•°", len(results_df))
                c2.metric("å½“å‰ç°‡æ•°é‡", n_clusters)
                c3.metric("å™ªéŸ³æ•°æ®æ•°", n_noise)
                
                st.dataframe(results_df.head(100), use_container_width=True)
            else:
                st.warning("æš‚æ— ç»“æœæ•°æ®")

        # === Tab 4: å¯¼å‡º ===
        with tab4:
            results_df = engine.get_results()
            if results_df is not None:
                col_fname1, col_fname2 = st.columns([2, 1])
                with col_fname1:
                    fname = st.text_input("å¯¼å‡ºæ–‡ä»¶å", "final_cluster_result")
                with col_fname2:
                    export_fmt = st.radio("æ ¼å¼", ["Excel", "CSV"], horizontal=True)
                
                # Excel ä¸‹è½½
                if export_fmt == "Excel":
                    import io
                    excel_buffer = io.BytesIO()
                    with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                        results_df.to_excel(writer, index=False, sheet_name='Cluster_Results')
                    excel_buffer.seek(0)
                    
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½ Excel",
                        data=excel_buffer,
                        file_name=f"{fname}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        type="primary"
                    )
                # CSV ä¸‹è½½
                else:
                    csv_data = results_df.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½ CSV",
                        data=csv_data,
                        file_name=f"{fname}.csv",
                        mime="text/csv",
                        type="primary"
                    )

    else:
        # å¦‚æœæ²¡æœ‰åŠ è½½æ•°æ®ï¼Œæ˜¾ç¤ºå ä½æç¤º
        if input_file is None:
            st.info("ğŸ‘ˆ è¯·åœ¨ä¸Šæ–¹é€‰æ‹© [åŠ è½½å†å²çŠ¶æ€] æˆ– [ä¸Šä¼ æ–°æ–‡ä»¶] ä»¥å¯ç”¨æ§åˆ¶å°ã€‚")

# =====================================================================
# èšç±»è¯„ä¼°é¡µé¢
# =====================================================================
elif page == "ğŸ“Š èšç±»è¯„ä¼°":
    st.title("ğŸ“Š èšç±»æ•ˆæœè¯„ä¼°")
    st.markdown("---")
    
    # [æ–°å¢] ä¼˜å…ˆæ£€æŸ¥ Session State
    if 'cluster_engine' in st.session_state and st.session_state['cluster_engine'] is not None:
        st.info("ğŸ’¡ æ­£åœ¨ä½¿ç”¨å†…å­˜ä¸­çš„èšç±»åˆ†æç»“æœã€‚")
        engine = st.session_state['cluster_engine']
        results_df = engine.get_results()
        embeddings = engine.get_embeddings()
        
        # ç›´æ¥å¼€å§‹è¯„ä¼°ï¼Œæ— éœ€ä¸Šä¼ 
        evaluator = ClusterEvaluator(results_df, embeddings)
        metrics = evaluator.compute_metrics()
        
        col1, col2, col3 = st.columns(3)
        with col1: st.metric("æ€»æ ·æœ¬æ•°", metrics['Total Samples'])
        with col2: st.metric("èšç±»ä¸ªæ•°", metrics['Valid Clusters'])
        with col3: st.metric("å™ªéŸ³æ¯”ä¾‹", metrics['Noise Ratio'])
        
        if 'Silhouette Score' in metrics and metrics['Silhouette Score'] != "N/A (ç°‡æ•°é‡ä¸è¶³)":
            col1, col2 = st.columns(2)
            with col1: st.metric("è½®å»“ç³»æ•°", metrics['Silhouette Score'])
            with col2: st.metric("CHåˆ†æ•°", metrics['CH Score'])
            
        # ç›¸ä¼¼åº¦åˆ†æ (å¦‚æœæœ‰)
        if st.button("è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ (å¯èƒ½è¾ƒæ…¢)"):
            with st.spinner("è®¡ç®—ä¸­..."):
                evaluator.analyze_similarity()
    else:
        # å›é€€åˆ°ä¸Šä¼ æ–‡ä»¶æ¨¡å¼
        input_file = st.file_uploader("ä¸Šä¼ èšç±»ç»“æœæ–‡ä»¶ (å¿…é¡»åŒ…å« Text å’Œ Cluster åˆ—)", type=["xlsx", "xls"], key="eval_input")
        
        if input_file is not None:
            try:
                with st.spinner("ğŸ“– è¯»å–æ–‡ä»¶..."):
                    results_df = pd.read_excel(input_file)
                
                # æ£€æŸ¥å¿…éœ€åˆ—
                if 'Text' not in results_df.columns or 'Cluster' not in results_df.columns:
                    st.error("âŒ æ–‡ä»¶å¿…é¡»åŒ…å« 'Text' å’Œ 'Cluster' åˆ—")
                else:
                    with st.spinner("ğŸ¤– åŠ è½½SBERTæ¨¡å‹å¹¶è®¡ç®—å‘é‡..."):
                        engine = TaxClusteringEngine(EMBEDDING_MODEL_NAME)
                        texts = results_df['Text'].tolist()
                        embeddings = engine.model.encode(texts, show_progress_bar=False)
                    
                    evaluator = ClusterEvaluator(results_df, embeddings)
                    # ... (åç»­æ˜¾ç¤ºé€»è¾‘åŒä¸Š)
                    metrics = evaluator.compute_metrics()
                    st.write(metrics)
                    
            except Exception as e:
                st.error(f"âŒ è¯„ä¼°å¤±è´¥: {str(e)}")

# =====================================================================
# LLMå…³é”®è¯æå–é¡µé¢
# =====================================================================
elif page == "ğŸ·ï¸ LLMå…³é”®è¯æå–":
    st.title("ğŸ·ï¸ LLMå…³é”®è¯æå–")
    st.markdown("ä½¿ç”¨å¤§æ¨¡å‹æ™ºèƒ½å½’çº³èšç±»å…³é”®è¯")
    st.markdown("---")
    
    st.subheader("ğŸ”‘ APIé…ç½®")
    col1, col2 = st.columns(2)
    with col1:
        api_key = st.text_input("API Key", type="password", help="è¾“å…¥ä½ çš„DeepSeek/OpenAI API Key")
    with col2:
        base_url = st.text_input("APIåœ°å€", "https://api.deepseek.com", help="APIç«¯ç‚¹åœ°å€")
    
    st.subheader("ğŸ“ æ•°æ®æº")
    input_file = st.file_uploader("ä¸Šä¼ èšç±»ç»“æœ", type=["xlsx", "xls"], key="llm_input")
    
    if input_file is not None and api_key and base_url:
        if st.button("ğŸš€ å¼€å§‹æå–å…³é”®è¯"):
            try:
                with st.spinner("ğŸ“– è¯»å–æ–‡ä»¶..."):
                    df = pd.read_excel(input_file)
                
                with st.spinner("ğŸ¤– åˆå§‹åŒ–LLMæå–å™¨..."):
                    extractor = LLMKeywordExtractor(
                        api_key=api_key,
                        base_url=base_url,
                        model="deepseek-chat"
                    )
                
                with st.spinner("â³ æ­£åœ¨è°ƒç”¨LLMæå–å…³é”®è¯... (è¯·è€å¿ƒç­‰å¾…)"):
                    df_result = extractor.extract_keywords(df, text_col='Text')
                
                # ä¿å­˜ç»“æœ
                output_path = os.path.join(OUTPUT_DIR, "llm_keywords_result.xlsx")
                save_excel(df_result, output_path)
                
                # æ˜¾ç¤ºç»“æœ
                st.subheader("ğŸ“‹ æå–ç»“æœ")
                display_df = df_result[['Cluster', 'LLM_Keywords']].drop_duplicates()
                st.dataframe(display_df, use_container_width=True)
                
                st.success(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
                
            except Exception as e:
                st.error(f"âŒ æå–å¤±è´¥: {str(e)}")
    else:
        st.warning("âš ï¸ è¯·å¡«å†™APIé…ç½®å’Œä¸Šä¼ æ–‡ä»¶")

# =====================================================================
# ç»“æœæŸ¥çœ‹é¡µé¢
# =====================================================================
elif page == "ğŸ“ˆ ç»“æœæŸ¥çœ‹":
    st.title("ğŸ“ˆ ç»“æœæŸ¥çœ‹ä¸å¯¼å‡º")
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“ åŠ è½½æ–‡ä»¶")
        result_file = st.file_uploader("é€‰æ‹©ç»“æœæ–‡ä»¶", type=["xlsx", "xls"])
    
    with col2:
        st.subheader("ğŸ” è¿‡æ»¤é€‰é¡¹")
        filter_noise = st.checkbox("éšè—å™ªéŸ³æ•°æ®", value=False)
    
    if result_file is not None:
        try:
            df = pd.read_excel(result_file)
            
            if filter_noise and 'Cluster' in df.columns:
                df = df[df['Cluster'] != -1]
            
            st.subheader("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
            st.metric("æ€»è¡Œæ•°", len(df))
            
            # æ˜¾ç¤ºæ•°æ®
            st.dataframe(df, use_container_width=True, height=400)
            
            # å¯¼å‡º
            st.subheader("ğŸ’¾ å¯¼å‡ºé€‰é¡¹")
            export_filename = st.text_input("å¯¼å‡ºæ–‡ä»¶å", "result_export.xlsx")
            if st.button("ğŸ’¾ å¯¼å‡ºä¸ºExcel"):
                export_path = os.path.join(OUTPUT_DIR, export_filename)
                save_excel(df, export_path)
                st.success(f"âœ… å·²å¯¼å‡ºåˆ°: {export_path}")
        
        except Exception as e:
            st.error(f"âŒ åŠ è½½å¤±è´¥: {str(e)}")

# =====================================================================
# é¡µè„š
# =====================================================================
st.markdown("---")
st.markdown("""
    <div style="text-align: center; color: #666; font-size: 12px;">
    <p>ğŸ¯ ç¨åŠ¡è¯‰æ±‚åˆ†æç³»ç»Ÿ Pro v2.0</p>
    </div>
""", unsafe_allow_html=True)